
Explainability can be (slightly different definition from the one given in the videos, where global still refers to the predictions but in a broader sense)

- global -> the overall ML model transparent and comprehensive

- local -> focus on explaining the model's individual predictions

Notice that:

Interpretability: how accurately a a ml model can associate a cause to an effect

Explainability: explaining the parameters to justify the results

Again, this difference doesn't exist in the videos, were these terms are used interchangeably


### Feature Importance

Indicates how useful each feature is relative to other features.

Can be used for variable selection or to address data leakage


### Vertex Explainable AI

Integrates feature attribution

Centered around instance level feature attributions

3 methods:

- sampled shapley (tabular data)

- integrate gradients (with images especially, but also tabular data)

- XRAI: based on integrated gradients (only images)


### Vertex AI Example-Based Explanations

For misclassification analysis, can help active learning


### Data Bias and Fairness

When data is not representative.

How to detect bias and problems:

- explainable AI feature attributions technique
- interactive console using What If Tool
- Language Interpretability Tool for NLP models

### ML Solution Readiness


2 concepts:

- Responsible AI

use tools to inspect and understand AI models:
- explainable AI
- Model cards
- TF open source toolkit

- Model Governance
A core function in companies that provides guidelines and processes to help employees

Human in the loop to review model output
Maintain model cards


### Set Up Explanations in Vertex AI

Custom trained model -> needs configure explanations

AutoML tabular classification -> no specific config


3 options:

- Online explanations: similar to predictions, return predictions with feature attribution
- Batch explanations (async)
- Local Kernel explanations (in user maanged vertex ai workbench)