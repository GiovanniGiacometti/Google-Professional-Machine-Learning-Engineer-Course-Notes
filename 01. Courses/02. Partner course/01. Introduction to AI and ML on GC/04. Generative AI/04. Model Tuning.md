
Fine tuning with custom data

- high computation
- high cost
- time consuming


Parameter efficient tuning:

- train only a subset of parameters

Adapter tuning

Reinforcement tuning

Distillation (exclusive to Google Cloud)

transfer knowledge from a larger model to a smaller model to optimize performance (using examples of reasonings and rationales)

---

In [[Vertex AI Studio]] you can " tune and distill"

2 options:

- supervised tuning
- reinforcement tuning (rlhf)

tuning dataset in cloud storage, jsonl file