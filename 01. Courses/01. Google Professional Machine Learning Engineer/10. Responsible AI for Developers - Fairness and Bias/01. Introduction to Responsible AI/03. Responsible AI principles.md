
Recommended practices to develop AI with responsible AI in mind:

- Human centered approach

Features with appropriate disclosures built in, clarity and control are crucial to a good user experience.

Engage with a diverse set of users and use-case scenario

- Identify multiple metrics to assess training and monitoring

Help understand tradeoff between errors

Performance across data slices
Ensure metrics are appropriate for the context and goal of the system

- Examine raw data directly

Data should be accurate
Data and data samples should be representative
Training-Serving skew shouldn't happen
Features should be predictive
No bias!

- Awareness of the limitations of your dataset and model

No mistake correlation for causation
Scope and coverage of training test
Communicate limitations to users when possible

- Test the AI system to ensure it's working as intended

Unit tests
Integration tests

Input drift
Gold standard dataset to test the system
Iterative user testing

poka-yoke principle: fail loudly basically

- Monitor and update the system continously after deployment

Analyze candidate model before deployment -> how will the update affect user experience?

