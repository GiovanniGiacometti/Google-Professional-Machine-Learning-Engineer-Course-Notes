
7 objectives to follow:

- AI should be socially beneficial -> pursue only if the overall likely benefits substantially exceed the foreseeable risks and downsides. The impact depends on how responsibly it is developed, no AI application is inherently absolutely beneficial

- AI should avoid creating or reinforcing unfair bias and unjust effect on people, particularly those related to sensitive characteristics such as race, ethnicity, gender, ability, and political or religious belief.

- AI should be built and tested for safety -> avoid unintended results that create risks of harm

- AI should be accountable to people -> feedback and explanations. For any project, we should provide appropriate opportunities for feedback, relevant explanations and appeal.

- AI should incorporate privacy design principles.

- AI should uphold high standards of scientific excellence:  we should work with a range of stakeholders to promote thoughtful leadership in this area, drawing on scientifically rigorous and multidisciplinary approaches.

- AI should be made available for uses that accord with these principles

4 areas not to purse

- Technologies that cause or are likely to cause overall harm
- Weapons or other technologies whose principal purpose of implementation is to cause injury
- Technologies that gather or use information for surveillance that violates internationally accepted norms.
- Technologies where the purpose contravenes widely accepted principles of international law and human rights