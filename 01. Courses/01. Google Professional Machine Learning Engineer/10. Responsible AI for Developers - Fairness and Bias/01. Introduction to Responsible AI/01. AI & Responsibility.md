
No AI model has 100% accuracy, and AI systems are complex.

This is because AI models are often under specified.

They perform well in the situation in which they are trained, but might not be robust or fair in new situations.

---

It's people who make decision
Each decision point requires consideration and evaluation to ensure that choices have been made responsibly

---

No wide consensus on what ethics should we take in mind when developing a model.

---

Notice that ethics is different from laws and policies

Law draws insights from ethics, and ethics inform policy but most ethical norms are not codified.

So we need to define what is ethical behavior:

- Ethics is what we ought to do, not the same as what is actually done or what most people say or think should be done.

- Ethics is what others can rightly blame us for not doing, even if we suffer no actual punishment.

- Ethics is what sustains our flourishing together in human society, ethics is an evolved tool for living well as social creatures.

---

Not only controversial use cases.

Without responsible AI practices, even seemingly innocuous or good intent, AI use cases could still cause ethical issues or unintended outcomes.

---

Responsible AI requires an understanding of the possible issues, limitations, or unintended consequences.

-> not a universal definition, formula or checklist.

Individuals and organization are developing according to their values and beliefs.

However, there are some shared themes: fairness, intepretability, privacy, safety

Following these:

- safer and more accountable products
- Better models -> get customer's trust
- Responsible innovation

