
If models are retrained, resulting parameters might be different

If the surface is non convex, we might end up in a different minima

---

Model training is slow:

What are the steps and the time complexities?

- compute derivative: # of data points and # of model parameters
- Update: # of model parameters
- check loss: # of data points and # of model parameters and the frequency in which we do it.

How to improve?

- Compute derivative on fewer data points -> it still works
**Minibatch gradient descend** -  can also be parallized

- Compute loss less frequently


