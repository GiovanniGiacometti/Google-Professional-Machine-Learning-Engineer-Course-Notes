
Relate to the 4th google principle for responsible ai -> be accountable to people

Also essential to the second principle, since interpretability is key to understand bias and thus be able to avoid it

It aims to understand ML models behaviour

What characteristics are used to judge?

In this course, interpretability (sometimes related to the system as a whole) and explainability (sometimes used for specific methods) are used interchangeably

---

Transparency -> many components are involved, each system should be able to document itself and be transparent

---

3 stakeholders that benefit:

- engineers -> increase understand
- users -> increase trust
- regulators -> make sure models are in compliance

---

Not easy (it's even difficult for people)

Model complexity (usually a tradeoff with explainability)

ML vs Traditional Software -> AI systems offer new challenges

