
TextVectorization -> raw strings into an encoded representation

---

Normalization -> feature wise normalization (standard)

---

Discretization -> bucket data into discrete ranges

---

Many categorical feature preprocessing

CategoryEncoding -> transform categorical
Hashing -> hashing trick
StringLookup -> given a vocab (or not, in this case it's learned with the function adapt()), transforms strings into integers. Can also provide a one hot output, multi hot output or a tf idf output
IntegerLookup -> same as above but with integers

Difference between CategoryEncoding and IntegerLookup?

From docs:
```
This layer (CategoryEncoding) provides options for condensing data into a categorical encoding when the total number of tokens are known in advance. It accepts integer values as inputs, and it outputs a dense or sparse representation of those inputs. For integer inputs where the total number of tokens is not known, use IntegerLookup instead.
```

---

2 options to apply preprocessing:

- make it part of the model ->it happens with its execution and benefits of gpu execution
- do it on the tf.data.Dataset -> processing happens on the CPU async. When running on TPU, preprocessing layers should be in the tf.data pipeline 

Even if this second option is chosen, it's good to also export an inference only end to end model that supports preprocessing layers

-> makes the model portable (especially to other runtimes)
-> reduce training-serving skew

---





