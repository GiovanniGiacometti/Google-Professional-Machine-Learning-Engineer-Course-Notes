
Performance should also consider predictions time

If Batch prediction, same considerations as the training (time, cost, scale)


Online predictions are different (the user is waiting for the prediction)

Almost always scale the predictions in microservices

Query per second is the measure

---

Strike the right balance between precomputing predictions for the top 20% of users and handling the rest via online predictions