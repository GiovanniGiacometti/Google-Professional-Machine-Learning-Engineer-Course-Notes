
Similar to mirror strategy but on more machines

Creates copy of the model on each device across all workers

Sync data parallelism

---

Here TF needs to know which machines are part of the cluster

![[Pasted image 20240929194731.png]]

One machine is the chief

---

![[Pasted image 20240929194810.png]]

The model has to be defined within the scope of the strategy as in this way it knows which parameters are to copied on all workers

---

Additional step to also synchronize with machines (increased overhead)

Data needs to be sharding

---

Saving the model

Chief worker save to a desired model directory, while workers will save to temporary directories