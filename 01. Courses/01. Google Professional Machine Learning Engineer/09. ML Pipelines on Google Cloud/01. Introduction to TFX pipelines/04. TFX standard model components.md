
**Trainer**

Both tf1 and keras estimators supported 
Parametrize training and eval arguments

Input:
- transform graph
- data
- schmea
- code (usually in a model.py file)

Produces:

- model in a SavedModel format (easy to share and deploy on a variety of environments)
- EvalSavedModel

---


**Tuner**

It works with trainer to identify the best hyperparameters.
It integrates with GC AI platform Optimizer for distributed training

---

**Evaluator**

2 artifacts:

- evaluation metrics
- model blessing: whether the model is ready for production (if performance is greater than a threshold)
---

**InfraValidator**

Evaluate whether the model is mechanically fine, used before pushing to production

Produces Serving infra blessing

---

**Pusher**

Requires blessing from other components (Evaluator, InfraValidator)

The output is a wrapper of the models according to the deployment target

---

**BulkInferer**

Include inference in the pipeline

Reads:

model
model blessing
unlabeled example from example gen

-> Inference Result proto

