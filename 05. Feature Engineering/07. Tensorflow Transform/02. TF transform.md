
3 possible places to do feature engineering.

One of them is within TF using feature_columns

It's efficient, if run on a gpu (then it has to be executed within the model, it has to be part of the graph). Moreover, all of this works if preprocessing is done on a single input only, can't rely on other values (such as a rolling averae )

Another option is Beam/Dataflow
It might be overkill if we are not requiring too many operations.

A third option is tf.transform. Limited to tf. methods but efficiently done.

----

It's an hybrid between apache beam and tensorflow

---

Beam -> works in the context of a stateful pipeline (such as time windows)
TF -> preprocessing based on the input only
TF Transform -> analyze and transform training data

![[Pasted image 20240915162402.png]]

Analysis -> Beam
Transform -> TF
![[Pasted image 20240915162521.png]]

