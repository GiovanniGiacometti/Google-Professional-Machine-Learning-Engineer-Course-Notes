
![[Pasted image 20240921215149.png]]

Cloud storage takes care of storing
Big Query can be used as a data source
Dataflow supports data processing

---

![[Pasted image 20240921215321.png]]

The tfx pipeline sdk translates the pipeline description into a Kubeflow Pipeline YAML file that can be executed with a Kubeflow Dag Runner.

The tfx pipeline is a kubeflow pipeline that is run on a Google Kubernetes engine cluster

The Argo workflow engine coordinates the pipeline's components and the pipeline ML metadata is stored on a persistent disk on your GKE instance
  
Depending on your pipeline runtime setting, your pipeline also enjoys secure access to underlying Google Cloud services.

---

For standard data and model components that use Apache Beam to implement data parallel pipelines, Google Cloud dataflow manages the distribution of component executor data processing workloads.

These include a custom ExampleGen for data stored in BigQuery, Google Cloud's data warehouse solution -> can take sql queries as inputs

Other custom components are available to integrate with google cloud.

Cloud AI platform runs on top of a Google Kubernetes engine cluster so your TFX pipeline has integrations to store pipeline artifacts on Cloud Storage, operational logs on Cloud logging, and ML metadata on Cloud SQL.